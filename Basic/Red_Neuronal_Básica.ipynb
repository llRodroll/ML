{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Red Neuronal Básica.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/llRodroll/ML/blob/main/Basic/Red_Neuronal_B%C3%A1sica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RAy5Fmw304z"
      },
      "source": [
        "# Red Neuronal - Básica\n",
        "\n",
        "La idea es codificar una red neuronal básica en la cual busquemos predicir un resultado.\n",
        "\n",
        "## Arquitectura de la RN\n",
        "\n",
        "Gráficamente la estructura de la neurona es:\n",
        "\n",
        "![Arquitectura RN](Basic_ANN.jpg)\n",
        "    Fuente: https://www.youtube.com/watch?v=kft1AJ9WVDk\n",
        "\n",
        "En este caso, se tienen los inputs y luego una capa que procesa y posteriormente el output. En otras palabras, es un Perceptron.\n",
        "\n",
        "## Datos\n",
        "\n",
        "Los datos con los cuales se va a trabajar son los siguientes:\n",
        "\n",
        "| Ejp || $x_1$ | $x_2$ | $x_3$ || $y$ | \n",
        "|-----||-------|-------|-------||-----|\n",
        "|  1  || 0     | 0     | 1     || 0   |\n",
        "|  2  || 1     | 1     | 1     || 1   |\n",
        "|  3  || 1     | 0     | 1     || 1   |\n",
        "|  4  || 0     | 1     | 1     || 0   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edbFUIuT3041"
      },
      "source": [
        "## Programar la RN\n",
        "\n",
        "Para tal fin se utilizará la libreria numpy para realizar los operaciones entre los vectores.\n",
        "Se crearán los datos input de training (la tabla anterior para $x_{1}, x_{2}$ y $x{3}$) mediante una matriz y los datos output ($y$) mediante un vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKK4rZ8H3042"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "training_inputs = np.array([[0,0,1],\n",
        "                            [1,1,1],\n",
        "                            [1,0,1],\n",
        "                            [0,1,1]])\n",
        "\n",
        "training_outputs = np.array([[0,1,1,0]]).T # transpuesto en la medida que y es un vector colummna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JXf0_-d3043"
      },
      "source": [
        "Con esto ya quedaría las $x$'s y la y de la Ilustración anterior.\n",
        "\n",
        "Lo siguiente sería establecer el vector de las ponderaciones $w$, para ello se \"inicializará\" el vector con valores aleatorios.\n",
        "Para mantener sencillo el ejemplo, se desea que estos valores aleatorios estén entre -1 y 1.\n",
        "\n",
        "Ahora bien, para lograr esto se utilizará una función que genera números aleatorios entre (0,1) de una distribución uniforme. Sin embargo, lo que se desea es que los números estén entre -1 y 1, por lo tanto se debe aplicar la propiedad de dicha distribución. A saber,\n",
        "\n",
        "Sea $z\\sim U(0,1)$, sean dos números tales que $b>a$. Entonces, $(b -a)z - a \\sim U(a,b)$. **REVISAR FÓRMULA**\n",
        "\n",
        "En este caso, $b=1$ y $a=-1$ y así $2z - 1 \\sim U(-1,1)$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4goJqb_-3043",
        "outputId": "1227665e-fa0b-4d0a-c2e9-f0f3c248ec9a"
      },
      "source": [
        "#np.random.seed(1)  # esto sirve para que todas las simulaciones sean iguales entre distintos computadores\n",
        "\n",
        "pesos = 2*np.random.random((3,1)) - 1 # las dimensiones de los pesos son 3 filas y una columna \n",
        "\n",
        "print('Valores iniciales aleatorios de los pesos:')\n",
        "print(pesos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valores iniciales aleatorios de los pesos:\n",
            "[[-0.84814272]\n",
            " [-0.61096015]\n",
            " [ 0.57590452]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V_81Cx13045"
      },
      "source": [
        "### La función $\\phi()$\n",
        "\n",
        "La función $\\phi()$ que está en la neurona tiene como objetivo convertir la suma ponderada de los pesos y los inputs en números que estén entre 0 y 1.\n",
        "\n",
        "Existen muchos tipos de funciones para realizar esto, sin embargo, para este caso se utiliza la función sigmoide que tiene la siguiente forma:\n",
        "\n",
        "$\\phi(z) = 1/(1 + e^{-z})$\n",
        "\n",
        "Con $z = \\sum_{i=1}^3 x_{i}w{i}$\n",
        "\n",
        "Para entender un poco mejor, el objetivo de la función veamos lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyMyzy5t3045",
        "outputId": "0b488c32-7c40-4483-d713-41cc48c92832"
      },
      "source": [
        "print('Resultado de z (multiplicar pesos por inputs)')\n",
        "print(np.dot(training_inputs,pesos))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultado de z (multiplicar pesos por inputs)\n",
            "[[ 0.57590452]\n",
            " [-0.88319836]\n",
            " [-0.2722382 ]\n",
            " [-0.03505564]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeLPMrmT3046"
      },
      "source": [
        "La función np.dot() realiza el producto punto entre $w$ y $x$ para obtener $z$.\n",
        "\n",
        "Note que el valor de $z$ está lejos de tener la forma que necesitamos. Por ejemplo, todos los valores dan negativos lo cual no es adecuado dado que en el vector de outputs NO HAY NEGATIVOS.\n",
        "\n",
        "Entonces, la función $\\phi()$ lo que hace es llevar cualquier resultado o número que de $z$ al intervalo (0,1).\n",
        "Para el caso puntual de la multiplicación anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRf_9hKz3046",
        "outputId": "9533e08c-0205-4b1e-be08-43b77eb2db31"
      },
      "source": [
        "z = np.dot(training_inputs,pesos)\n",
        "print('Resultado del sigmoide sobre z')\n",
        "print(1/(1+np.exp(z)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultado del sigmoide sobre z\n",
            "[[0.35987551]\n",
            " [0.70748456]\n",
            " [0.5676423 ]\n",
            " [0.50876301]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX6LWGpv3047"
      },
      "source": [
        "Ahora sí, todos los valores están más acordes a los outputs que necesitamos. Pero todavia no al 100%, para ello tendremos que hacer algo adicional más adelante.\n",
        "\n",
        "De formal más general, la función sigmoide tiene este comportamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "U0SL1s3R3047",
        "outputId": "63040db3-8964-4d4a-d4bd-f09ea03d1a9d"
      },
      "source": [
        "z = np.arange(-20,20)  # secuencia de números desde -20 hasta 20\n",
        "phi = 1/(1+np.exp(-z))  # sigmoide\n",
        "\n",
        "import matplotlib.pyplot as plt # libreria para gráficos\n",
        "plt.plot(z,phi)\n",
        "plt.ylabel('$\\phi()$')\n",
        "plt.xlabel('z')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e9YmWdu3048"
      },
      "source": [
        "## Training de la RN\n",
        "\n",
        "Bien, ahora que ya tenemos todos los elementos de la RN podemos pasar hacer el entrenamiento.\n",
        "Qué quiere decir esto? El entrenamiento consiste en encontrar aquellos $w$ que hacen que el output de la RN $\\hat{y}$ sea lo más cercano al output real $y$.\n",
        "\n",
        "Para ello, contamos con diferentes alternativas, aunque solo vamos hacer dos. La primera consiste en decirle al programa que repita muchas veces un procedimiento hasta que el resultado que obtengamos nos sea satisfactorio.\n",
        "\n",
        "La segunda comprende algo más de formalismo y establecemos una métrica de \"éxito\" para el programa.\n",
        "\n",
        "### Primera Alternativa\n",
        "\n",
        "Empecemos con la primera, La idea es realizar el siguiente procedimiento:\n",
        "\n",
        "1. Tome los inputs de los datos para training y \"paselos\" por la neurona para obtener un $\\hat{y}$.\n",
        "2. Calcule el error de estimación, es decir la diferencia entre lo estimado y lo real: $\\hat{y} - y$.\n",
        "    \n",
        "    Hasta este paso se llama FORWARD PROPAGATION.\n",
        "\n",
        "3. Dependendiendo de la severidad del error, ajuste los pesos.\n",
        "\n",
        "    3.1. Para ello, se toma la derivada de la función $\\phi(z)$ que en este caso sería $\\phi(z)' = z(1-z)$.\n",
        "    \n",
        "    3.2. Luego se multiplica dicha derivada por el error de estimación $\\hat{y} - y$.\n",
        "    \n",
        "    3.3. Así, el ajuste a los pesos será $adj.pesos = (\\hat{y} - y)(z(1-z))$.\n",
        "        \n",
        "4. Repetir el proceso 2,000 veces.\n",
        "    Hasta acá se llama BACKWARDPROPAGATION."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71XCY-pQ3048",
        "outputId": "16ccae04-7864-499b-ca71-12125dda64b2"
      },
      "source": [
        "# Para facilitar el cálculo se definen las funciones de sigmoide y su derivada\n",
        "\n",
        "def sigmoide(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "def der_sig(z):\n",
        "    return z*(1-z)\n",
        "\n",
        "for iteration in range(20000):\n",
        "\n",
        "    input_layer = training_inputs\n",
        "    \n",
        "    outputs_est = sigmoide(np.dot(input_layer,pesos))\n",
        "    \n",
        "    error = training_outputs - outputs_est  \n",
        "    \n",
        "    ad_pesos = error*der_sig(outputs_est)\n",
        "    \n",
        "    pesos += np.dot(input_layer.T,ad_pesos) # el += significa p.j.: a=10; a+= 5 entonces a=15.\n",
        "\n",
        "print('Pesos despues del Training')\n",
        "print(pesos)\n",
        "\n",
        "print('Outputs estimados')\n",
        "print(outputs_est)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pesos despues del Training\n",
            "[[10.38012762]\n",
            " [-0.20692007]\n",
            " [-4.9840775 ]]\n",
            "Outputs estimados\n",
            "[[0.00679971]\n",
            " [0.99445393]\n",
            " [0.9954859 ]\n",
            " [0.00553578]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv-atOWg3049"
      },
      "source": [
        "### Segunda Alternativa\n",
        "\n",
        "Cómo se mencionó, la idea es establecer una métrica de éxito con el objetivo de dercile a la RN cuando ha encontrado una solución.\n",
        "\n",
        "En este sentido, se utiliza una medida conocida en el pronóstico de series de tiempo llamada RMSE o Raíz del Error Cuadratico Medio:\n",
        "\n",
        "\\begin{equation}\n",
        "RMSE = \\sqrt{\\sum_{i=1}^{N}{\\frac{(\\hat{y_{i}}-y_{i})^2}{N}}}\n",
        "\\end{equation}\n",
        "\n",
        "Donde $\\hat{y}_i$ es el ouput estimado por la RN, $y_{i}$ es el output verdadero u observado y $N$ es el número total de outputs. Esta medida nos indica el error promedio de la estimación o pronóstico. Además, en el contexto de las RN a esta función, y a otras más, se les denomina función de costo e intuitivamente lo que se buscaría es minimizar ese costo. Es decir, buscar que la RN se \"desache\" lo menos posible en promedio.\n",
        "\n",
        "Formalmente, toca minimizar el RMSE cambiando las ponderaciones (o weigths):\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\min_{w} \\quad & \\sqrt{\\sum_{i=1}^{N}{\\frac{(\\hat{y_{i}}-y_{i})^2}{N}}}\\\\\n",
        "\\textrm{s.t.} \\quad & \\hat{y_{i}} = \\phi(z_{i})\\,\\textrm{para todo}\\,i=1,2,...,N\\\\\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "Bien, antes de pasar a programar es necesario dejar varias cosas claras de la notación utilizada y el uso de matrices y vectores. Por qué? Porque la imagen que se presentó al inicio solo representa el proceso para \"un\" conjunto de inputs que dan como resultado \"un\" solo output. Y en ahora, se busca representar el problema de tal forma que incluya todos lo inputs y outpus.\n",
        "\n",
        "**Primero**, note que se escribió $w$, sin subíndices. Esto indica que $w$ es un vector de la forma:\n",
        "\n",
        "\\begin{equation}\n",
        "w=\\left[\\begin{array}{c}w_{1}\\\\w_{2}\\\\\\vdots\\\\w_{K}\\end{array}\\right]\n",
        "\\end{equation}\n",
        "\n",
        "Con $K$ como el número de ponderaciones (o weigths), que en el caso puntual de este ejemplo $K=3$.\n",
        "\n",
        "**Segundo**, la expresión $\\hat{y_{i}} = \\phi(z_{i})$ se puede descomponer de la siguiente forma:\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y_{i}} = \\phi\\left(\\sum_{j=1}^{K}{x_{i,j}w_{j}}\\right)\\,\\textrm{para todo}\\,i=1,2,...,N\n",
        "\\end{equation}\n",
        "\n",
        "Cómo ya se habia mencionado $N$ es el número de input o outputs y aquí quizás una aclaración. Recordar que la \"base de datos\" del ejemplo es:\n",
        "\n",
        "\n",
        "| Ejp || $x_1$ | $x_2$ | $x_3$ || $y$ | \n",
        "|-----||-------|-------|-------||-----|\n",
        "|  1  || 0     | 0     | 1     || 0   |\n",
        "|  2  || 1     | 1     | 1     || 1   |\n",
        "|  3  || 1     | 0     | 1     || 1   |\n",
        "|  4  || 0     | 1     | 1     || 0   |\n",
        "\n",
        "Es decir, se tienen $4$ ejemplos u observaciones por lo tanto $N=4$. Ahora, note que los inputs y el output también se pueden escribir en notación matricial. Particularmente:\n",
        "\n",
        "\\begin{equation}\n",
        "X=\\left[\\begin{array}{ccc}\n",
        "x_{1,1} & x_{1,2} & x_{1,3}\\\\\n",
        "x_{2,1} & x_{2,2} & x_{2,3}\\\\\n",
        "x_{3,1} & x_{3,2} & x_{3,3}\\\\\n",
        "x_{4,1} & x_{4,2} & x_{4,3}\n",
        "\\end{array}\\right]=\\left[\\begin{array}{ccc}\n",
        "0 & 0 & 1\\\\\n",
        "1 & 1 & 1\\\\\n",
        "1 & 0 & 1\\\\\n",
        "0 & 1 & 1\n",
        "\\end{array}\\right]\n",
        "\\end{equation}\n",
        "\n",
        "Donde, el elemnto $x_{i,j}$ representa la observación $i$ del input $j$. Ahora, para el caso del ouput:\n",
        "\n",
        "\\begin{equation}\n",
        "Y=\\left[\\begin{array}{c}\n",
        "y_{1}\\\\\n",
        "y_{2}\\\\\n",
        "y_{3}\\\\\n",
        "y_{4}\n",
        "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
        "0\\\\\n",
        "1\\\\\n",
        "1\\\\\n",
        "0\n",
        "\\end{array}\\right]\n",
        "\\end{equation}\n",
        "\n",
        "y,\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{Y}=\\left[\\begin{array}{c}\n",
        "\\hat{y_{1}}\\\\\n",
        "\\hat{y_{2}}\\\\\n",
        "\\hat{y_{3}}\\\\\n",
        "\\hat{y_{4}}\n",
        "\\end{array}\\right]\n",
        "\\end{equation}\n",
        "\n",
        "**Tercero**, utilizando la notación anterior y haciendo uso de algebra líneal, el problema de optimización se puede escribir de forma más compacta:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\min_{w} \\quad & \\frac{\\left\\Vert \\hat{Y}-Y\\right\\Vert }{N}\\\\\n",
        "\\textrm{s.t.} \\quad & \\hat{Y} = \\phi(Xw)\\\\\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "O alternativamente:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\min_{w} \\quad & \\frac{\\left\\Vert \\phi(Xw)-Y\\right\\Vert }{N}\\\\\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "Dado lo anterior, ahora sí a programar..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9iEj0Tc304-",
        "outputId": "43e8b398-f2a2-416b-92da-5b4b6323fd86"
      },
      "source": [
        "# Es necesario instalar scipy\n",
        "from scipy.optimize import minimize  # paquete de la libreria scipy. minimize es la función específica\n",
        "\n",
        "# definir la función de costo\n",
        "\n",
        "def cost(w):\n",
        "    # Renormbrar objetos a la notación actual\n",
        "\n",
        "    X = training_inputs\n",
        "    Y = np.array([[0,1,1,0]])\n",
        "\n",
        "    return np.linalg.norm(sigmoide(np.dot(X,w))-Y)/len(Y) #sigmoide es la función creada en la primera alternativa\n",
        "\n",
        "# NOTA: LA FUNCIÓN NO ESTÁ OPTIMZIADA PARA QUE FUNCIONE EN CUALQUIER EJEMPLO. SE PUEDE MEJORAR\n",
        "\n",
        "# valores iniciales para los pesos \n",
        "np.random.seed(1)\n",
        "w0 = 2*np.random.random((3,1)) - 1 \n",
        "\n",
        "# ensayo funcionamiento de la función cost\n",
        "\n",
        "print(\"El RMSE con los valores iniciales de los pesos es\",cost(w0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El RMSE con los valores iniciales de los pesos es 2.1642091376618446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygsqpAZJ304_",
        "outputId": "667d45ed-e99b-4c45-fe8f-c18c773d1b9f"
      },
      "source": [
        "# La optimización\n",
        "\n",
        "min_cost  = minimize(cost,w0,method='nelder-mead',options={'xatol': 1e-8, 'disp': True})\n",
        "pesos_opt = min_cost.x \n",
        "\n",
        "X = training_inputs\n",
        "Y = training_outputs\n",
        "\n",
        "print(min_cost)\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"El RMSE mínimo alcanzado fue: \", min_cost.fun)\n",
        "print(\"Los pesos óptimos son: \", pesos_opt)\n",
        "print(\"El output estimado es: \", sigmoide(np.dot(X,pesos_opt)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.000000\n",
            "         Iterations: 111\n",
            "         Function evaluations: 308\n",
            " final_simplex: (array([[ 759.12042717,   43.39187978, -416.2456604 ],\n",
            "       [ 759.12042717,   43.39187978, -416.2456604 ],\n",
            "       [ 759.12042718,   43.39187978, -416.2456604 ],\n",
            "       [ 759.12042718,   43.39187978, -416.2456604 ]]), array([0., 0., 0., 0.]))\n",
            "           fun: 0.0\n",
            "       message: 'Optimization terminated successfully.'\n",
            "          nfev: 308\n",
            "           nit: 111\n",
            "        status: 0\n",
            "       success: True\n",
            "             x: array([ 759.12042717,   43.39187978, -416.2456604 ])\n",
            "--------------------------------------------------\n",
            "El RMSE mínimo alcanzado fue:  0.0\n",
            "Los pesos óptimos son:  [ 759.12042717   43.39187978 -416.2456604 ]\n",
            "El output estimado es:  [1.68580203e-181 1.00000000e+000 1.00000000e+000 1.17939836e-162]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEjatBIi305A",
        "outputId": "85ab2d6e-d264-4610-c6c1-dbc5ebd39589"
      },
      "source": [
        "np.linalg.norm(outputs_est-Y)/len(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002828186484068906"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7JDp6v305A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}